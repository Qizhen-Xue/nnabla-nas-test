# Copyright (c) 2020 Sony Corporation. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json

import nnabla_nas
from nnabla_nas.utils.estimator import estimator
from nnabla_nas.utils.profiler.helpers import uid
from nnabla_nas.utils.estimator.estimator import Estimator

class NNablaLatencyEstimator(Estimator):

    def __init__(self, latency_table_json, runtime, cap_value=0.0):
        """
        Args: 
          latency_table_json (str): Path to the latency table.
          runtime (str): Key to the runtime in ["cpu:float", "cudnn:float", "cudnn:half"]
          cap_value (float): Cap value if the estimation is negative.
        """
        # Latency Table
        with open(latency_table_json) as fp:
            self._all_latency_table = json.load(fp)
        self._runtime = runtime
        self._cap_value = cap_value

        self._skip_modules = (nnabla_nas.module.identity.Identity,
                              nnabla_nas.module.dropout.Dropout)

        # Pickup one runtime
        self._latency_table = {}
        for k in self._all_latency_table.keys():
            self._latency_table[k] = self._all_latency_table[k][runtime]

        self._scales = {}
        self._biases = {}

        
        % for r, s in runtime_scales.items():
        self._scales["${r}"] = ${s}
        % endfor
        % for r, b in runtime_biases.items():
        self._biases["${r}"] = ${b}
        % endfor

        self._scale = self._scales[runtime]
        self._bias = self._biases[runtime]

    def get_estimation(self, net):
        """Returns the estimation of the whole module."""
        modules = [m for _, m in net.get_modules() if len(m.modules) == 0 and m.need_grad and not isinstance(m, self._skip_modules)]

        accum_latency = 0.0
        for m in modules:
            accum_latency += self._latency_table[uid(m)][self._runtime]
        estimated_latency = max(self._scale * accum_latency + self._bias, self._cap_value)
        return estimated_latency
